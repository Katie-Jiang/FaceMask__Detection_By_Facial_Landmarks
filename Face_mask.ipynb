{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cc2e904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import time\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import cv2\n",
    "import random\n",
    "import dlib\n",
    "import argparse\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fa335a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 22:27:01.262 python[19581:481406] TSM AdjustCapsLockLEDForKeyTransitionHandling - _ISSetPhysicalKeyboardCapsLockLED Inhibit\n"
     ]
    }
   ],
   "source": [
    "TYPE = {0:\"No Mask on Face\", 1:\"Nose not Covered\", 2:\"Mouth not Covered\", 3:\"Correctly Wear Mask\"}\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "#cascPath = os.path.dirname(cv2.__file__)+\"/data/haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "tf.executing_eagerly()\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session())\n",
    "model_mouth = tf.keras.models.load_model('model_r_mouth', custom_objects={\"tf\": tf})\n",
    "model_nose = tf.keras.models.load_model('model_r_nose', custom_objects={\"tf\": tf})\n",
    "\n",
    "prev_faces = []\n",
    "prev_type = \"Waiting\"\n",
    "prev_outline = []\n",
    "prev_outline_nose = []\n",
    "prev_outline_mouth = []\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "    frame = cv2.flip(frame,1)\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=7,\n",
    "        minSize=(100,100),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        faces = prev_faces\n",
    "    else:\n",
    "        prev_faces = faces\n",
    "\n",
    "    # Draw a rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        # type(face) == <class 'numpy.ndarray'>\n",
    "        face_box = cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        image = frame[y:y+h, x:x+w]\n",
    "        image = cv2.resize(image, (500, 500))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if len(detector(image)) != 0:\n",
    "            rect = detector(image)[0]\n",
    "            sp = predictor(image, rect)\n",
    "            landmarks = np.array([[p.x, p.y] for p in sp.parts()])\n",
    "            outline = landmarks[[*range(67,29,-1)]]\n",
    "            outline_nose = landmarks[[*range(36,29,-1)]]\n",
    "            outline_mouth = landmarks[[*range(67,49,-1)]]\n",
    "\n",
    "            prev_outline = outline\n",
    "            prev_outline_nose = outline_nose\n",
    "            prev_outline_mouth = outline_mouth\n",
    "        else:\n",
    "            outline = prev_outline\n",
    "            outline_nose = prev_outline_nose\n",
    "            outline_mouth = prev_outline_mouth\n",
    "\n",
    "        if len(outline) != 0 and len(outline_nose) != 0 and len(outline_mouth) != 0:\n",
    "            # get the nose and mouth area\n",
    "            crop_nose = image[min(outline_nose[:,1]):max(outline_nose[:,1]), min(outline_nose[:,0]):max(outline[:,0])]\n",
    "            crop_mouth = image[min(outline_mouth[:, 1]):max(outline_mouth[:, 1]), min(outline_mouth[:, 0]):max(outline[:, 0])]\n",
    "            # crop_nose_mouth = image[min(outline[:,1]):max(outline[:,1]), min(outline[:,0]):max(outline[:,0])]\n",
    "            \n",
    "            crop_nose = cv2.resize(crop_nose, (150,150))\n",
    "            crop_mouth = cv2.resize(crop_mouth, (150,150))\n",
    "            # crop_nose_mouth = cv2.resize(crop_nose_mouth, (150,150))\n",
    "\n",
    "            # cv2.imwrite(\"crop_nose.png\", crop_nose)\n",
    "            # cv2.imwrite(\"crop_mouth.png\", crop_mouth)\n",
    "            # cv2.imwrite(\"crop_nose_mouth.png\", crop_nose_mouth)\n",
    "\n",
    "            label_m, prob_m = model_mouth.predict(np.expand_dims(crop_mouth, 0))\n",
    "            # print(('MOUTH Predicted labels: %d' % label_m[0]))\n",
    "            # print(('Probability: %f' % prob_m[0]))\n",
    "            label_n, prob_n = model_nose.predict(np.expand_dims(crop_nose, 0))\n",
    "            # print(('NOSE Predicted labels: %d' % label_n[0]))\n",
    "            # print(('Probability: %f' % prob_n[0]))\n",
    "\n",
    "            if label_m == 0 and label_n == 0:\n",
    "                status = TYPE[3]\n",
    "            elif label_m == 1 and label_n == 1:\n",
    "                status = TYPE[0]\n",
    "            elif label_n:\n",
    "                status = TYPE[1]\n",
    "            elif label_m:\n",
    "                status = TYPE[2]\n",
    "\n",
    "            prev_type = status\n",
    "            if status == TYPE[3]:\n",
    "                cv2.putText(face_box, status, (x, y-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n",
    "            else:\n",
    "                cv2.putText(face_box, status, (x, y-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "\n",
    "        else:\n",
    "            # type <- model\n",
    "            # type = TYPE[0]\n",
    "            if prev_type == TYPE[3]:\n",
    "                cv2.putText(face_box, prev_type, (x, y-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n",
    "            else:\n",
    "                cv2.putText(face_box, prev_type, (x, y-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    time.sleep(0.08)\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a2f707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
